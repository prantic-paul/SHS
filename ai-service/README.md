# ğŸ¤– AI Service â€“ Smart Health Synchronizer

**RAG-based Medical Chatbot powered by Google Gemini, Pinecone Vector Database, and LangChain for intelligent, context-aware healthcare assistance.**

---

## ğŸ“‹ Overview

The AI Service is an advanced **Retrieval-Augmented Generation (RAG)** chatbot designed to provide accurate, context-aware medical information to SHS platform users. By combining the power of:

- **Google Gemini 1.5 Flash** - Latest LLM for natural language understanding
- **Pinecone Vector Database** - Fast semantic search over medical knowledge
- **LangChain** - Orchestration framework for RAG pipeline
- **HuggingFace Embeddings** - Convert text to vector representations

The AI Service offers **intelligent medical advice** that is grounded in authoritative medical documents, reducing hallucinations and improving factual accuracy.

**Key Capabilities:**
- ğŸ’¬ Natural conversational interface for health queries
- ğŸ“š Context-aware responses from medical knowledge base
- ğŸ” Semantic search across medical documents
- ğŸ¯ Specialized medical prompting strategies
- âš¡ Fast response times with vector similarity search
- ğŸ›¡ï¸ Safety disclaimers and medical ethics compliance

**Important Note:** This AI assistant provides general health information only. It is **NOT** a substitute for professional medical diagnosis or treatment. Users are always advised to consult qualified healthcare providers.

---

## ğŸ¯ Problem It Solves

### Healthcare Information Gap

**Problems:**
1. **Information Overload** - Patients struggle to find reliable health information online
2. **Medical Jargon** - Complex medical terminology confuses non-experts
3. **Misinformation** - Unverified health advice spreads easily
4. **Accessibility** - Limited access to immediate medical consultation
5. **Question Complexity** - Users don't know what to ask or how to describe symptoms

### Our Solution

The AI Service bridges this gap by:

âœ… **Accurate Information** - Responses grounded in medical documents, not just LLM training data  
âœ… **Plain Language** - Translates complex medical concepts into understandable terms  
âœ… **24/7 Availability** - Instant responses anytime, anywhere  
âœ… **Personalized Guidance** - Context-aware answers based on user queries  
âœ… **Doctor Recommendations** - Suggests appropriate specialist types for conditions  
âœ… **Safe Advice** - Always includes disclaimers and encourages professional consultation

**Use Cases:**
- Explaining medical test results
- Understanding medication side effects
- Identifying when to seek urgent care
- Preparing questions before doctor appointments
- Learning about medical conditions and treatments
- Finding appropriate specialist recommendations

---

## ğŸ§  AI Approach

### Retrieval-Augmented Generation (RAG)

Traditional chatbots rely solely on LLM knowledge, which can be:
- âŒ **Outdated** - Training data is static
- âŒ **Unreliable** - Prone to hallucinations
- âŒ **Generic** - Lacks domain-specific expertise

**RAG Solves This:**

```
User Query â†’ Embedding â†’ Vector Search â†’ Relevant Docs â†’ Gemini (with context) â†’ Answer
```

### How It Works

1. **Document Ingestion**
   - Medical documents are split into chunks
   - Each chunk is converted to embeddings (vectors)
   - Embeddings stored in Pinecone with metadata

2. **Query Processing**
   - User query is converted to embedding
   - Similarity search in Pinecone finds relevant chunks
   - Top K most relevant documents retrieved

3. **Context Injection**
   - Retrieved documents added to system prompt
   - User query appended
   - Full context sent to Gemini

4. **Answer Generation**
   - Gemini generates response grounded in provided context
   - Response formatted with clear structure
   - Safety disclaimers added automatically

### Why RAG for Healthcare?

- ğŸ“– **Up-to-date Information** - Knowledge base can be updated anytime
- ğŸ¯ **Domain Expertise** - Uses curated medical documents
- ğŸ”¬ **Verifiable** - Responses can be traced to source documents
- ğŸ›¡ï¸ **Reduced Hallucinations** - LLM constrained by retrieved context
- âš¡ **Efficient** - Only relevant information sent to LLM, reducing tokens

---

## ğŸ—ï¸ Architecture Flow

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface (React)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP Request (Chat Message)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Backend API (Django)                            â”‚
â”‚  â€¢ Validates JWT token                                               â”‚
â”‚  â€¢ Stores chat history in database                                   â”‚
â”‚  â€¢ Forwards request to AI Service                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ POST /chat
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Service (FastAPI - Port 8001)                  â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    1. Query Embedding                         â”‚   â”‚
â”‚  â”‚    HuggingFace Embeddings (all-MiniLM-L6-v2)                â”‚   â”‚
â”‚  â”‚    Converts user query to 384-dimensional vector             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚                                       â”‚
â”‚                                â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    2. Semantic Search                         â”‚   â”‚
â”‚  â”‚    Query: Pinecone Vector DB                                 â”‚   â”‚
â”‚  â”‚    Returns: Top 5 most relevant medical document chunks      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚                                       â”‚
â”‚                                â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    3. Context Assembly                        â”‚   â”‚
â”‚  â”‚    LangChain RetrievalQA Chain                               â”‚   â”‚
â”‚  â”‚    Combines: System Prompt + Retrieved Docs + User Query     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚                                       â”‚
â”‚                                â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    4. Response Generation                     â”‚   â”‚
â”‚  â”‚    Google Gemini 1.5 Flash                                   â”‚   â”‚
â”‚  â”‚    Generates context-aware medical response                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ JSON Response
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Backend API (Django)                          â”‚
â”‚  â€¢ Receives AI response                                              â”‚
â”‚  â€¢ Stores in chat history                                            â”‚
â”‚  â€¢ Forwards to frontend                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface (React)                        â”‚
â”‚  Displays AI response in chat interface                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Framework** | FastAPI | 0.108.0 | Async web framework |
| **LLM** | Google Gemini | 1.5 Flash | Response generation |
| **Vector DB** | Pinecone | Latest | Semantic search |
| **Orchestration** | LangChain | 0.1.0 | RAG pipeline |
| **Embeddings** | HuggingFace | all-MiniLM-L6-v2 | Text vectorization |
| **HTTP Client** | requests | 2.31.0 | API calls |
| **Environment** | python-dotenv | 1.0.0 | Config management |
| **Validation** | Pydantic | 2.5.0 | Data validation |

---

## ğŸ“š Data Sources

### Medical Knowledge Base

The AI Service is grounded in curated medical documents including:

1. **Medical Textbooks** - General medicine, symptoms, diseases
2. **Clinical Guidelines** - Treatment protocols, diagnostics
3. **Health Information** - Common conditions, medications, preventive care
4. **Specialist Directories** - When to consult specific specialists

### Document Processing Pipeline

```python
# 1. Document Loading
documents = TextLoader("medical_docs/").load()

# 2. Text Splitting (chunks of 500 tokens, 50 overlap)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = text_splitter.split_documents(documents)

# 3. Embedding Generation
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# 4. Vector Store Creation
vectorstore = Pinecone.from_documents(
    chunks, 
    embeddings, 
    index_name="shs-medical"
)
```

---

## ğŸ¯ Prompting Strategy

### System Prompt Design

```python
SYSTEM_PROMPT = """
You are a helpful medical assistant for the Smart Health Synchronizer platform.

Guidelines:
1. **Be Accurate**: Base responses on provided medical documents
2. **Be Clear**: Use simple language, explain medical terms
3. **Be Helpful**: Suggest next steps (book appointment, see specialist)
4. **Be Safe**: Always include disclaimer about consulting healthcare professionals
5. **Be Empathetic**: Show understanding and compassion

IMPORTANT DISCLAIMERS:
- You are NOT a doctor and cannot provide medical diagnosis
- Your advice is for informational purposes only
- Users should always consult qualified healthcare providers
- In emergencies, users should call emergency services immediately

Context from medical documents:
{context}

User Question: {question}
"""
```

### Response Structure

```
ğŸ“‹ **Explanation**
[Clear explanation of medical topic]

ğŸ” **Key Points**
- Point 1
- Point 2

ğŸ‘¨â€âš•ï¸ **Recommended Specialist**
[Specialist type if applicable]

âš ï¸ **Important Disclaimer**
This information is for educational purposes only. Consult a healthcare provider.
```

---

## ğŸŒ API Endpoints

### POST /chat - Send Chat Message

**Request:**
```bash
curl -X POST http://localhost:8001/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What are the symptoms of diabetes?",
    "user_id": "user_123"
  }'
```

**Response:**
```json
{
  "response": "ğŸ“‹ **Diabetes Symptoms**\n\nCommon symptoms:\n\nğŸ” **Key Symptoms**\n- Increased thirst\n- Frequent urination\n- Extreme hunger\n- Fatigue\n- Blurred vision\n\nğŸ‘¨â€âš•ï¸ **Recommended Specialist**\nConsult an **Endocrinologist**\n\nâš ï¸ **Disclaimer**\nConsult a healthcare provider for diagnosis.",
  "timestamp": "2026-01-22T10:30:00Z",
  "sources": ["diabetes_overview.pdf"]
}
```

### GET /health - Health Check

**Request:**
```bash
curl http://localhost:8001/health
```

**Response:**
```json
{
  "status": "healthy",
  "service": "ai-service",
  "pinecone": "connected",
  "gemini": "available"
}
```

---

## âš ï¸ Limitations

1. **Not a Medical Diagnosis Tool** - Cannot replace professional medical consultation
2. **Knowledge Base Scope** - Limited to documents in vector database
3. **Language Support** - Primary: English
4. **Privacy** - User queries sent to external services (Gemini, Pinecone)
5. **Response Time** - 2-5 seconds depending on query
6. **Response Quality** - May occasionally provide incomplete information

### Safety Measures

âœ… Always includes medical disclaimer  
âœ… Encourages professional consultation  
âœ… Suggests appropriate specialists  
âœ… Refuses to diagnose conditions  
âœ… Provides emergency guidance when needed

---

## ğŸš€ Future Enhancements

1. **Enhanced Knowledge Base** - Expand to 10,000+ medical documents
2. **Fine-Tuned Models** - Custom fine-tuned Gemini model on medical data
3. **Personalization** - User medical history integration (with consent)
4. **Advanced Features** - Image analysis, voice input/output, multi-turn memory
5. **Quality Improvements** - Source citation, confidence scores, feedback loop
6. **Integration** - Direct booking, EHR integration, medication checker

---

## âš™ï¸ Environment Variables

Create `.env` file in `ai-service/` directory:

```env
# Google Gemini API
GOOGLE_API_KEY=your-gemini-api-key-here

# Pinecone Configuration
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-east1-gcp
PINECONE_INDEX_NAME=shs-medical

# Model Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_MODEL=gemini-1.5-flash
MAX_TOKENS=1024
TEMPERATURE=0.3

# Application Settings
PORT=8001
DEBUG=True
LOG_LEVEL=INFO
```

---

## ğŸš€ Setup & Run

### Prerequisites
- Python 3.10+
- Google Gemini API key
- Pinecone account and API key

### Installation

```bash
cd ai-service
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
nano .env  # Add your API keys
```

### Initialize Vector Database

```bash
python scripts/ingest_documents.py
```

### Run Service

```bash
uvicorn main:app --reload --port 8001
```

Service runs at `http://localhost:8001`

### API Documentation
- **Swagger UI:** http://localhost:8001/docs
- **ReDoc:** http://localhost:8001/redoc

---

## ğŸ“„ License

Part of Smart Health Synchronizer - MIT License

---

## ğŸ‘¨â€ğŸ’» Author

**Prantic Paul**  
GitHub: [@prantic-paul](https://github.com/prantic-paul)  
Email: pranticpaulshimul@gmail.com
